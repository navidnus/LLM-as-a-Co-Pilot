{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **1) Installing OpenAI**"
      ],
      "metadata": {
        "id": "nR0ij-PbbMxk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEX58I77DM7U",
        "outputId": "7230d52b-4922-48c5-a884-b02873ba47ed",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.33.0\n",
            "Collecting striprtf\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Installing collected packages: striprtf\n",
            "Successfully installed striprtf-0.0.26\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.1)\n",
            "Installing collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n",
            "install: missing destination file operand after 'tqdm'\n",
            "Try 'install --help' for more information.\n"
          ]
        }
      ],
      "source": [
        "#Installing OpenAI\n",
        "!pip install openai\n",
        "!pip install striprtf\n",
        "!pip install python-docx\n",
        "!install tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2) Importing the necessary packages**"
      ],
      "metadata": {
        "id": "34pwtIMnbEoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import openai\n",
        "from google.colab import drive\n",
        "import os\n",
        "from striprtf.striprtf import rtf_to_text\n",
        "from docx import Document\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "P2mq6U9JEl_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Choosing the Model and API Key"
      ],
      "metadata": {
        "id": "cCKi2JM1bVLL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPEN_AI_API_KEY = \"\"\n",
        "OPEN_AI_MODEL = \"gpt-4o\""
      ],
      "metadata": {
        "id": "lQZxsdewbeTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Dealing with path, folder, and files"
      ],
      "metadata": {
        "id": "GM5VNMsTpSso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert RTF to plain text using striprtf\n",
        "def convert_rtf_to_text(rtf_file_path):\n",
        "    with open(rtf_file_path, 'r', encoding='utf-8') as file:\n",
        "        rtf_content = file.read()\n",
        "    plain_text = rtf_to_text(rtf_content)\n",
        "    return plain_text\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Directory containing both the RTF files and the Word file with the main prompt\n",
        "directory_path = '/content/drive/My Drive/Navid_trying API/'\n",
        "\n",
        "# Path to your Word file containing the main prompt\n",
        "word_file_path = os.path.join(directory_path, 'prompt_stem.docx')  # Update this filename\n",
        "\n",
        "# Read the main prompt directly\n",
        "doc = Document(word_file_path)\n",
        "main_prompt = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "# List all RTF files in the directory\n",
        "rtf_files = [f for f in os.listdir(directory_path) if f.endswith('.rtf')]\n",
        "\n",
        "# Prepare a list to collect results for the CSV\n",
        "results = []\n",
        "\n",
        "# Loop through each RTF file, convert it to plain text, and generate a completion\n",
        "for rtf_file in tqdm(rtf_files, desc=\"Processing\"):\n",
        "    rtf_file_path = os.path.join(directory_path, rtf_file)\n",
        "    # Extract plain text from the RTF file\n",
        "    rtf_text = convert_rtf_to_text(rtf_file_path)\n",
        "    # Concatenate the main prompt with the RTF text\n",
        "    full_prompt = main_prompt + \"\\n\\n\" + rtf_text\n",
        "    # Generate a completion using OpenAI API\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": full_prompt},\n",
        "        ],\n",
        "    )\n",
        "    # Extract the generated text\n",
        "    generated_text = response.choices[0].message.content.strip()\n",
        "    # Add the results to the list\n",
        "    results.append([rtf_file, full_prompt, generated_text])\n",
        "\n",
        "# Save the results to a CSV file\n",
        "df = pd.DataFrame(results, columns=['File Name', 'Full Prompt', 'Generated Response'])\n",
        "df.to_csv(os.path.join(directory_path, 'results.csv'), index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQGHWNw3paWv",
        "outputId": "8b811495-8998-44bc-d9b7-6227e6765cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 15/15 [02:35<00:00, 10.35s/it]\n"
          ]
        }
      ]
    }
  ]
}